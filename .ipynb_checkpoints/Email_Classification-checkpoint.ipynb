{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19ab64c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac2e69f7",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "class Data_Preprocessing:\n",
    "    emails= pd.DataFrame()\n",
    "    \n",
    "    def __init__(self):\n",
    "        print('Object created......Data Preprocessing starts')\n",
    "        print('----------------------------------------------------------------')\n",
    "    \n",
    "    def read_data(self,input_dataset):\n",
    "        global emails\n",
    "        \n",
    "        print('Reading Data from the csv file')\n",
    "        emails= pd.read_csv(input_dataset, encoding='latin-1')\n",
    "        \n",
    "        print('Prints the first 5 rows of the dataframe')\n",
    "        print(emails.head())\n",
    "        print('----------------------------------------------------------------')\n",
    "        \n",
    "        print('Number of emails in each label')\n",
    "        print(emails.Label.value_counts())\n",
    "        print('----------------------------------------------------------------')\n",
    "        \n",
    "        print('A copy of the Email content is created')\n",
    "        text_feat= emails['Email'].copy()\n",
    "        print('----------------------------------------------------------------')\n",
    "        \n",
    "        print('Calling the text_process function to remove punctuation and stopwords.')\n",
    "        print('----------------------------------------------------------------')\n",
    "        print('This might take few minutes')\n",
    "        text_feat= text_feat.apply(self.text_process)\n",
    "        print('\\n')\n",
    "        print(text_feat.head())\n",
    "        \n",
    "        return text_feat\n",
    "\n",
    "    \n",
    "    def text_process(self, text):\n",
    "        #the text is translated by replacing empty string wth empty string and deleting all the characters found in string.punctuation\n",
    "        text= text.translate(str.maketrans('','',string.punctuation))\n",
    "        text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
    "        return \" \".join(text)\n",
    "    \n",
    "    def stemmer(self, text):\n",
    "        #stemming of content\n",
    "        text = text.split()\n",
    "        words = \"\"\n",
    "        for i in text:\n",
    "                stemmer = SnowballStemmer(\"english\")\n",
    "                words += (stemmer.stem(i))+\" \"\n",
    "        return words\n",
    "        \n",
    "    def feature_creation(self, text_feat):\n",
    "        print('Initialize the TfIdfVectorizer')\n",
    "        vectorizer= TfidfVectorizer(stop_words='english')\n",
    "        features = vectorizer.fit_transform(text_feat)\n",
    "        print('***********Features created successfully*******************')\n",
    "        print('--------------------------------')\n",
    "        print('Features: ', features.shape)\n",
    "        print('\\n')\n",
    "        return features\n",
    "    \n",
    "    def featcreation_countvector(self, text_feat):\n",
    "        print('Initialize the count vector')\n",
    "        vector_count= CountVectorizer()\n",
    "        features_count= vector_count.fit_transform(text_feat)\n",
    "        print('Features using count vectorizer created successfully')\n",
    "        print('----------------------------------')\n",
    "        print('Features_count: ', features_count.shape)\n",
    "        print('\\n')\n",
    "        return features_count\n",
    "                \n",
    "    def split_train_test(self, features):\n",
    "        global emails\n",
    "        features_train, features_test, labels_train, labels_test = train_test_split(features, emails['Label'], test_size=0.3, random_state=111)\n",
    "        print('Features_train: ', features_train.shape)\n",
    "        print('Features_test: ', features_test.shape)\n",
    "        print('Labels_train: ', labels_train.shape)\n",
    "        print('Labels_test: ', labels_test.shape)\n",
    "        print('\\n')\n",
    "        return features_train, features_test, labels_train, labels_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb7e6bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process_one_email(self, text):\n",
    "        #the text is translated by replacing empty string wth empty string and deleting all the characters found in string.punctuation\n",
    "        text= text.translate(str.maketrans('','',string.punctuation))\n",
    "        text = [word for word in text.split() if word.lower() not in stopwords.words('english')]\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d292aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dataset='./Datasets/final_dataset.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7912d7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object created......Data Preprocessing starts\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Creatig object of class Data_Preprocessing\n",
    "Processed_dataset= Data_Preprocessing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e858f93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data from the csv file\n",
      "Prints the first 5 rows of the dataframe\n",
      "                                               Email   Label  Length\n",
      "0   cvs of candidates for rac support role  these...  NORMAL     126\n",
      "1   http : / / www . joelpittet . com  hello ,  i...    SPAM     940\n",
      "2   market internet access - no investment needed...    SPAM     294\n",
      "3    Greetings!!   I come to you with a sincere h...   FRAUD    2878\n",
      "4   the best possible mortgage  has your mortgage...    SPAM     568\n",
      "----------------------------------------------------------------\n",
      "Number of emails in each label\n",
      "NORMAL    1000\n",
      "SPAM      1000\n",
      "FRAUD     1000\n",
      "Name: Label, dtype: int64\n",
      "----------------------------------------------------------------\n",
      "A copy of the Email content is created\n",
      "----------------------------------------------------------------\n",
      "Calling the text_process function to remove punctuation and stopwords.\n",
      "----------------------------------------------------------------\n",
      "This might take few minutes\n",
      "\n",
      "\n",
      "0    cvs candidates rac support role three guys ava...\n",
      "1    http www joelpittet com hello visited www joel...\n",
      "2    market internet access investment needed marke...\n",
      "3    Greetings come sincere heart believing Almight...\n",
      "4    best possible mortgage mortgage search got fru...\n",
      "Name: Email, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Read data from the csv file, then removal of stopwords and punctuation\n",
    "text_feat= Processed_dataset.read_data(input_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca1ac62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "vectorizer= TfidfVectorizer(stop_words='english')\n",
    "vectorizer.fit_transform(text_feat)\n",
    "\n",
    "abc_model = pickle.load(open('model/abc.pkl', 'rb'))\n",
    "bc_model = pickle.load(open('model/bc.pkl', 'rb'))\n",
    "dtc_model = pickle.load(open('model/dtc.pkl', 'rb'))\n",
    "etc_model = pickle.load(open('model/etc.pkl', 'rb'))\n",
    "knc_model = pickle.load(open('model/knc.pkl', 'rb'))\n",
    "mnb_model = pickle.load(open('model/mnb.pkl', 'rb'))\n",
    "rfc_model = pickle.load(open('model/rfc.pkl', 'rb'))\n",
    "svc_model = pickle.load(open('model/svc.pkl', 'rb'))\n",
    "lrc_model = pickle.load(open('model/lrc.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d28200b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type anything  Greetings!!   I come to you with a sincere heart believing in Almighty Allah that you will consider my plight and come to help and also benefit from me=2E   I am Mrs=2E Amina Mohammed=2C cousin and Personal Assistant to former Nigeria Head of State=2C Late General Sanni Abacha who died on the 8th July 1998 while in power=2E Before I proceed please accept my apology for the embarrassment this mail might cause you for coming from a total stranger who you do not know=2E Actually I got your contact from the Internet=3B please do not feel bad about it because I am compelled to reach you due to urgent need to safeguard the money in question=2E Once again=2C forgive me and come to my aid=2E Please read the following carefully=2E   Sometime in early 1997=2C my boss late Gen=2E Sanni Abacha entrusted to me the sum of US$20=2E5M in cash =28Twenty million=2C five hundred thousand US dollars=29 due to the trust and confidence he had in me=2E This money was meant for campaign in is self-succession bid but unfortunately he suddenly died before actualization of his aspiration=2E This amount of $20=2E5M in CASH was deposited with a security company=2C which I will disclose in subsequent mail in a giant trunk box as diplomatic consignments In agreement with Mr=2EMohammed Abacha who is the son of Late General Abacha and the heir to the money=2E I write to solicit your Assistance for the money to be transferred to your custody=2E Note that Mr=2EMohammed Abacha is currently in detention by the present Nigeria Government for reasons linked to activities of his father when he was in power=2E Now based on the business trust I have on you=2C I would want you to come forward and receive this consignment containing the !  money in cash on our behalf from the security company for subsequent disbursement between you and us=2E Understand that we are soliciting your assistance because the present Nigerian Government is seizing=2Ffreezing any Bank Account or valuables belonging to the late Head of State's family and relatives=2E Infact we do not have enough money now to sustain our family so=2C I will appreciate if you can consider our plight and assist us=2EFor your assistance=2C we have agreed to compensate you with 20% of the total amount =28$20=2E5=29 while the remaining 80% is for us=2E We hope to invest part of our share in your country on viable area of investment as you may advise us=2E   If you are interested you will need to visit the Security Company for clearance of the consignment=2E I assure you that the transaction is 100% risk free=2E Please I implore you to keep this transaction absolutely secret against negative exposure=2E I would want you to contact me immediately so that we can proceed with the business=2E You should please on reply enclose your private telephone=2C fax number so that we can have more confidential correspondence=2E   \n",
      "['FRAUD']\n",
      "['FRAUD']\n",
      "['FRAUD']\n",
      "['FRAUD']\n",
      "['FRAUD']\n",
      "['FRAUD']\n",
      "['FRAUD']\n",
      "['FRAUD']\n"
     ]
    }
   ],
   "source": [
    "X = input(\"Type anything\")\n",
    "Y =  vectorizer.transform([X])\n",
    "\n",
    "# AdaBoost Classifier\n",
    "predict_out_abc = abc_model.predict(Y)\n",
    "# Bagging Classifier\n",
    "predict_out_bc = bc_model.predict(Y)\n",
    "# Decision Tree Classifier\n",
    "predict_out_dtc = dtc_model.predict(Y)\n",
    "# ExtraTrees Classifier\n",
    "predict_out_etc = etc_model.predict(Y)\n",
    "# K-Nearest Neighbour\n",
    "predict_out_knc = knc_model.predict(Y)\n",
    "# Multinomial Naive Bayes\n",
    "predict_out_mnb = mnb_model.predict(Y)\n",
    "# Random Forest Classifier\n",
    "predict_out_rfc = rfc_model.predict(Y)\n",
    "# Support Vector Machine\n",
    "predict_out_svc = svc_model.predict(Y)\n",
    "\n",
    "print(predict_out_abc)\n",
    "print(predict_out_bc)\n",
    "print(predict_out_dtc)\n",
    "print(predict_out_etc)\n",
    "print(predict_out_knc)\n",
    "print(predict_out_mnb)\n",
    "print(predict_out_rfc)\n",
    "print(predict_out_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a6262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
